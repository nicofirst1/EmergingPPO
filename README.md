# EmergingPPO



## useful links
- PPO code : https://github.com/huggingface/trl/blob/v0.7.9/trl/trainer/ppo_trainer.py
- PPO example:  https://huggingface.co/docs/trl/ppo_trainer
- Base paper:  https://openreview.net/pdf?id=-Yzz6vlX7V-
- Paper repo:  https://github.com/hcoxec/variable_compositionality